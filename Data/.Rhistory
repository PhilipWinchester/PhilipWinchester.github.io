StepToPoint <- Parameters + GradientVectorNormalised
print(Parameters)
print(GradientVectorNormalised)
print(StepToPoint)
LLLoop <- 0
# Adding GradientVectorNormalised until we have maxemised the LL
while(LL(Match_Data, Parameters=StepToPoint) > LL(Match_Data, Parameters=PresentPoint)){
PresentPoint <- StepToPoint
StepToPoint <- PresentPoint + GradientVectorNormalised
LLLoop <- LLLoop + 1
}
print(paste("LLLoop is "  ,toString(LLLoop)))
# If there has been less than one itteration in the while loop and the step size is smaller than the maximum, then we increase the step size
if((LLLoop < 2 & Step != n | Step == n & LLLoop == 0) & DevideByNMod){
Mult <- Mult + 1
Step <- Mult*m
}
Parameters <- PresentPoint
}
# Second bit to adjust Gamma
# Working out if we need to increase or decrease gamma
sign <- GradientVectorFinder(Match_Data, Parameters)[-2]/abs(GradientVectorFinder(Match_Data, Parameters)[-2])
# Change in 0.01 incraments until we have maxemised LL
PresentPoint <- Parameters
StepToPoint <- PresentPoint
StepToPoint[-2] <- StepToPoint[-2] + sign*0.01
While(LL(Match_Data, Parameters=StepToPoint) > LL(Match_Data, Parameters=PresentPoint)){
PresentPoint <- StepToPoint
StepToPoint[-2] <- StepToPoint[-2] + sign*0.01
}
Parameters <- PresentPoint
print(GradientVectorFinder(Match_Data, Parameters))
Alpha <- Parameters[1:length(Teams)]
Beta <- Parameters[(length(Teams)+1):(length(Teams)*2)]
Gamma <- Parameters[length(Teams)*2+1]
Rho <- Parameters[length(Teams)*2+2]
Results <- data.frame(Teams, Alpha, Beta, Gamma, Rho)
return(Results)
}
Optimise <- function(Match_Data,n = 1000 , m = 10 , DevideByNMod = FALSE, Condition = 0.01){
# Takes some match data and returns
Teams <- sort(unique(Match_Data$HomeTeam))
# Setting all Parameters equal to 1 at first
Parameters <- rep(1,2*length(Teams)+2)
# Setting gamma equal to 1.4 and rho equal to 0
Parameters[2*length(Teams)+1] <- 1.4
Parameters[2*length(Teams)+2] <- -0.05
# Making StartParameters
StartParameters <- rep(0,2*length(Teams)+2)
# Setting the multiplier and step, step is how big the gradient vector is (invesly proportional)
Mult <- 0
Step <- 0
if(DevideByNMod){
Mult <- 1
Step <- m
}
count <- 0
# NMod just finds the length betweent he vectores
while(NMod(Parameters-StartParameters,1) > Condition | (Mult < ((n/m)+1) & DevideByNMod)){
count <- count + 1
print(paste("count is "  ,toString(count)))
# Saving what wha have from the start
StartParameters <- Parameters
# Finding gradient
GradientVector <- GradientVectorFinder(Match_Data, Parameters)
# Normalising (Avergage of alhpas is 1), and adjusting the length
GradientVectorNormalised <- NormalisingTheGradientVector(GradientVector,Step, DevideByNMod = DevideByNMod)
print(paste("step is "  ,toString(Step)))
PresentPoint <- Parameters
StepToPoint <- Parameters + GradientVectorNormalised
print(Parameters)
print(GradientVectorNormalised)
print(StepToPoint)
LLLoop <- 0
# Adding GradientVectorNormalised until we have maxemised the LL
while(LL(Match_Data, Parameters=StepToPoint) > LL(Match_Data, Parameters=PresentPoint)){
PresentPoint <- StepToPoint
StepToPoint <- PresentPoint + GradientVectorNormalised
LLLoop <- LLLoop + 1
}
print(paste("LLLoop is "  ,toString(LLLoop)))
# If there has been less than one itteration in the while loop and the step size is smaller than the maximum, then we increase the step size
if((LLLoop < 2 & Step != n | Step == n & LLLoop == 0) & DevideByNMod){
Mult <- Mult + 1
Step <- Mult*m
}
Parameters <- PresentPoint
}
# Second bit to adjust Gamma
# Working out if we need to increase or decrease gamma
sign <- GradientVectorFinder(Match_Data, Parameters)[-2]/abs(GradientVectorFinder(Match_Data, Parameters)[-2])
# Change in 0.01 incraments until we have maxemised LL
PresentPoint <- Parameters
StepToPoint <- PresentPoint
StepToPoint[-2] <- StepToPoint[-2] + sign*0.01
While(LL(Match_Data, Parameters=StepToPoint) > LL(Match_Data, Parameters=PresentPoint)){
PresentPoint <- StepToPoint
StepToPoint[-2] <- StepToPoint[-2] + sign*0.01
}
Parameters <- PresentPoint
print(GradientVectorFinder(Match_Data, Parameters))
Alpha <- Parameters[1:length(Teams)]
Beta <- Parameters[(length(Teams)+1):(length(Teams)*2)]
Gamma <- Parameters[length(Teams)*2+1]
Rho <- Parameters[length(Teams)*2+2]
Results <- data.frame(Teams, Alpha, Beta, Gamma, Rho)
return(Results)
}
# prints
Results <- Optimise(Match_Data, DevideByNMod = TRUE, Condition = 0) # If we run this, we will se that all params but gamma are in good shape. could have 2nd bit where we optemise thi
Optimise <- function(Match_Data,n = 1000 , m = 10 , DevideByNMod = FALSE, Condition = 0.01){
# Takes some match data and returns
Teams <- sort(unique(Match_Data$HomeTeam))
# Setting all Parameters equal to 1 at first
Parameters <- rep(1,2*length(Teams)+2)
# Setting gamma equal to 1.4 and rho equal to 0
Parameters[2*length(Teams)+1] <- 1.4
Parameters[2*length(Teams)+2] <- -0.05
# Making StartParameters
StartParameters <- rep(0,2*length(Teams)+2)
# Setting the multiplier and step, step is how big the gradient vector is (invesly proportional)
Mult <- 0
Step <- 0
if(DevideByNMod){
Mult <- 1
Step <- m
}
count <- 0
# NMod just finds the length betweent he vectores
while(NMod(Parameters-StartParameters,1) > Condition | (Mult < ((n/m)+1) & DevideByNMod)){
count <- count + 1
print(paste("count is "  ,toString(count)))
# Saving what wha have from the start
StartParameters <- Parameters
# Finding gradient
GradientVector <- GradientVectorFinder(Match_Data, Parameters)
# Normalising (Avergage of alhpas is 1), and adjusting the length
GradientVectorNormalised <- NormalisingTheGradientVector(GradientVector,Step, DevideByNMod = DevideByNMod)
print(paste("step is "  ,toString(Step)))
PresentPoint <- Parameters
StepToPoint <- Parameters + GradientVectorNormalised
print(Parameters)
print(GradientVectorNormalised)
print(StepToPoint)
LLLoop <- 0
# Adding GradientVectorNormalised until we have maxemised the LL
while(LL(Match_Data, Parameters=StepToPoint) > LL(Match_Data, Parameters=PresentPoint)){
PresentPoint <- StepToPoint
StepToPoint <- PresentPoint + GradientVectorNormalised
LLLoop <- LLLoop + 1
}
print(paste("LLLoop is "  ,toString(LLLoop)))
# If there has been less than one itteration in the while loop and the step size is smaller than the maximum, then we increase the step size
if((LLLoop < 2 & Step != n | Step == n & LLLoop == 0) & DevideByNMod){
Mult <- Mult + 1
Step <- Mult*m
}
Parameters <- PresentPoint
}
# Second bit to adjust Gamma
# Working out if we need to increase or decrease gamma
sign <- GradientVectorFinder(Match_Data, Parameters)[-2]/abs(GradientVectorFinder(Match_Data, Parameters)[-2])
print(sign)
# Change in 0.01 incraments until we have maxemised LL
PresentPoint <- Parameters
StepToPoint <- PresentPoint
StepToPoint[-2] <- StepToPoint[-2] + sign*0.01
While <- 0
While(LL(Match_Data, Parameters=StepToPoint) > LL(Match_Data, Parameters=PresentPoint)){
While <- 1 + While
print(While)
PresentPoint <- StepToPoint
StepToPoint[-2] <- StepToPoint[-2] + sign*0.01
}
Parameters <- PresentPoint
print(GradientVectorFinder(Match_Data, Parameters))
Alpha <- Parameters[1:length(Teams)]
Beta <- Parameters[(length(Teams)+1):(length(Teams)*2)]
Gamma <- Parameters[length(Teams)*2+1]
Rho <- Parameters[length(Teams)*2+2]
Results <- data.frame(Teams, Alpha, Beta, Gamma, Rho)
return(Results)
}
Optimise <- function(Match_Data,n = 1000 , m = 10 , DevideByNMod = FALSE, Condition = 0.01){
# Takes some match data and returns
Teams <- sort(unique(Match_Data$HomeTeam))
# Setting all Parameters equal to 1 at first
Parameters <- rep(1,2*length(Teams)+2)
# Setting gamma equal to 1.4 and rho equal to 0
Parameters[2*length(Teams)+1] <- 1.4
Parameters[2*length(Teams)+2] <- -0.05
# Making StartParameters
StartParameters <- rep(0,2*length(Teams)+2)
# Setting the multiplier and step, step is how big the gradient vector is (invesly proportional)
Mult <- 0
Step <- 0
if(DevideByNMod){
Mult <- 1
Step <- m
}
count <- 0
# NMod just finds the length betweent he vectores
while(NMod(Parameters-StartParameters,1) > Condition | (Mult < ((n/m)+1) & DevideByNMod)){
count <- count + 1
print(paste("count is "  ,toString(count)))
# Saving what wha have from the start
StartParameters <- Parameters
# Finding gradient
GradientVector <- GradientVectorFinder(Match_Data, Parameters)
# Normalising (Avergage of alhpas is 1), and adjusting the length
GradientVectorNormalised <- NormalisingTheGradientVector(GradientVector,Step, DevideByNMod = DevideByNMod)
print(paste("step is "  ,toString(Step)))
PresentPoint <- Parameters
StepToPoint <- Parameters + GradientVectorNormalised
print(Parameters)
print(GradientVectorNormalised)
print(StepToPoint)
LLLoop <- 0
# Adding GradientVectorNormalised until we have maxemised the LL
while(LL(Match_Data, Parameters=StepToPoint) > LL(Match_Data, Parameters=PresentPoint)){
PresentPoint <- StepToPoint
StepToPoint <- PresentPoint + GradientVectorNormalised
LLLoop <- LLLoop + 1
}
print(paste("LLLoop is "  ,toString(LLLoop)))
# If there has been less than one itteration in the while loop and the step size is smaller than the maximum, then we increase the step size
if((LLLoop < 2 & Step != n | Step == n & LLLoop == 0) & DevideByNMod){
Mult <- Mult + 1
Step <- Mult*m
}
Parameters <- PresentPoint
}
' Second bit to adjust Gamma
# Working out if we need to increase or decrease gamma
sign <- GradientVectorFinder(Match_Data, Parameters)[-2]/abs(GradientVectorFinder(Match_Data, Parameters)[-2])
print(sign)
# Change in 0.01 incraments until we have maxemised LL
PresentPoint <- Parameters
StepToPoint <- PresentPoint
StepToPoint[-2] <- StepToPoint[-2] + sign*0.01
While <- 0
While(LL(Match_Data, Parameters=StepToPoint) > LL(Match_Data, Parameters=PresentPoint)){
While <- 1 + While
print(While)
PresentPoint <- StepToPoint
StepToPoint[-2] <- StepToPoint[-2] + sign*0.01
}
Parameters <- PresentPoint'''
print(GradientVectorFinder(Match_Data, Parameters))
Alpha <- Parameters[1:length(Teams)]
Beta <- Parameters[(length(Teams)+1):(length(Teams)*2)]
Gamma <- Parameters[length(Teams)*2+1]
Rho <- Parameters[length(Teams)*2+2]
Results <- data.frame(Teams, Alpha, Beta, Gamma, Rho)
return(Results)
}
Optimise <- function(Match_Data,n = 1000 , m = 10 , DevideByNMod = FALSE, Condition = 0.01){
# Takes some match data and returns
Teams <- sort(unique(Match_Data$HomeTeam))
# Setting all Parameters equal to 1 at first
Parameters <- rep(1,2*length(Teams)+2)
# Setting gamma equal to 1.4 and rho equal to 0
Parameters[2*length(Teams)+1] <- 1.4
Parameters[2*length(Teams)+2] <- -0.05
# Making StartParameters
StartParameters <- rep(0,2*length(Teams)+2)
# Setting the multiplier and step, step is how big the gradient vector is (invesly proportional)
Mult <- 0
Step <- 0
if(DevideByNMod){
Mult <- 1
Step <- m
}
count <- 0
# NMod just finds the length betweent he vectores
while(NMod(Parameters-StartParameters,1) > Condition | (Mult < ((n/m)+1) & DevideByNMod)){
count <- count + 1
print(paste("count is "  ,toString(count)))
# Saving what wha have from the start
StartParameters <- Parameters
# Finding gradient
GradientVector <- GradientVectorFinder(Match_Data, Parameters)
# Normalising (Avergage of alhpas is 1), and adjusting the length
GradientVectorNormalised <- NormalisingTheGradientVector(GradientVector,Step, DevideByNMod = DevideByNMod)
print(paste("step is "  ,toString(Step)))
PresentPoint <- Parameters
StepToPoint <- Parameters + GradientVectorNormalised
print(Parameters)
print(GradientVectorNormalised)
print(StepToPoint)
LLLoop <- 0
# Adding GradientVectorNormalised until we have maxemised the LL
while(LL(Match_Data, Parameters=StepToPoint) > LL(Match_Data, Parameters=PresentPoint)){
PresentPoint <- StepToPoint
StepToPoint <- PresentPoint + GradientVectorNormalised
LLLoop <- LLLoop + 1
}
print(paste("LLLoop is "  ,toString(LLLoop)))
# If there has been less than one itteration in the while loop and the step size is smaller than the maximum, then we increase the step size
if((LLLoop < 2 & Step != n | Step == n & LLLoop == 0) & DevideByNMod){
Mult <- Mult + 1
Step <- Mult*m
}
Parameters <- PresentPoint
}
' Second bit to adjust Gamma
# Working out if we need to increase or decrease gamma
sign <- GradientVectorFinder(Match_Data, Parameters)[-2]/abs(GradientVectorFinder(Match_Data, Parameters)[-2])
print(sign)
# Change in 0.01 incraments until we have maxemised LL
PresentPoint <- Parameters
StepToPoint <- PresentPoint
StepToPoint[-2] <- StepToPoint[-2] + sign*0.01
While <- 0
While(LL(Match_Data, Parameters=StepToPoint) > LL(Match_Data, Parameters=PresentPoint)){
While <- 1 + While
print(While)
PresentPoint <- StepToPoint
StepToPoint[-2] <- StepToPoint[-2] + sign*0.01
}
Parameters <- PresentPoint'''
print(GradientVectorFinder(Match_Data, Parameters))
Alpha <- Parameters[1:length(Teams)]
Beta <- Parameters[(length(Teams)+1):(length(Teams)*2)]
Gamma <- Parameters[length(Teams)*2+1]
Rho <- Parameters[length(Teams)*2+2]
Results <- data.frame(Teams, Alpha, Beta, Gamma, Rho)
return(Results)
}
Optimise <- function(Match_Data,n = 1000 , m = 10 , DevideByNMod = FALSE, Condition = 0.01){
# Takes some match data and returns
Teams <- sort(unique(Match_Data$HomeTeam))
# Setting all Parameters equal to 1 at first
Parameters <- rep(1,2*length(Teams)+2)
# Setting gamma equal to 1.4 and rho equal to 0
Parameters[2*length(Teams)+1] <- 1.4
Parameters[2*length(Teams)+2] <- -0.05
# Making StartParameters
StartParameters <- rep(0,2*length(Teams)+2)
# Setting the multiplier and step, step is how big the gradient vector is (invesly proportional)
Mult <- 0
Step <- 0
if(DevideByNMod){
Mult <- 1
Step <- m
}
count <- 0
# NMod just finds the length betweent he vectores
while(NMod(Parameters-StartParameters,1) > Condition | (Mult < ((n/m)+1) & DevideByNMod)){
count <- count + 1
print(paste("count is "  ,toString(count)))
# Saving what wha have from the start
StartParameters <- Parameters
# Finding gradient
GradientVector <- GradientVectorFinder(Match_Data, Parameters)
# Normalising (Avergage of alhpas is 1), and adjusting the length
GradientVectorNormalised <- NormalisingTheGradientVector(GradientVector,Step, DevideByNMod = DevideByNMod)
print(paste("step is "  ,toString(Step)))
PresentPoint <- Parameters
StepToPoint <- Parameters + GradientVectorNormalised
print(Parameters)
print(GradientVectorNormalised)
print(StepToPoint)
LLLoop <- 0
# Adding GradientVectorNormalised until we have maxemised the LL
while(LL(Match_Data, Parameters=StepToPoint) > LL(Match_Data, Parameters=PresentPoint)){
PresentPoint <- StepToPoint
StepToPoint <- PresentPoint + GradientVectorNormalised
LLLoop <- LLLoop + 1
}
print(paste("LLLoop is "  ,toString(LLLoop)))
# If there has been less than one itteration in the while loop and the step size is smaller than the maximum, then we increase the step size
if((LLLoop < 2 & Step != n | Step == n & LLLoop == 0) & DevideByNMod){
Mult <- Mult + 1
Step <- Mult*m
}
Parameters <- PresentPoint
}
print(GradientVectorFinder(Match_Data, Parameters))
Alpha <- Parameters[1:length(Teams)]
Beta <- Parameters[(length(Teams)+1):(length(Teams)*2)]
Gamma <- Parameters[length(Teams)*2+1]
Rho <- Parameters[length(Teams)*2+2]
Results <- data.frame(Teams, Alpha, Beta, Gamma, Rho)
return(Results)
}
Optimise <- function(Match_Data,n = 1000 , m = 10 , DevideByNMod = FALSE, Condition = 0.01){
# Takes some match data and returns
Teams <- sort(unique(Match_Data$HomeTeam))
# Setting all Parameters equal to 1 at first
Parameters <- rep(1,2*length(Teams)+2)
# Setting gamma equal to 1.4 and rho equal to 0
Parameters[2*length(Teams)+1] <- 1.4
Parameters[2*length(Teams)+2] <- -0.05
# Making StartParameters
StartParameters <- rep(0,2*length(Teams)+2)
# Setting the multiplier and step, step is how big the gradient vector is (invesly proportional)
Mult <- 0
Step <- 0
if(DevideByNMod){
Mult <- 1
Step <- m
}
count <- 0
# NMod just finds the length betweent he vectores
while(NMod(Parameters-StartParameters,1) > Condition | (Mult < ((n/m)+1) & DevideByNMod)){
count <- count + 1
print(paste("count is "  ,toString(count)))
# Saving what wha have from the start
StartParameters <- Parameters
# Finding gradient
GradientVector <- GradientVectorFinder(Match_Data, Parameters)
# Normalising (Avergage of alhpas is 1), and adjusting the length
GradientVectorNormalised <- NormalisingTheGradientVector(GradientVector,Step, DevideByNMod = DevideByNMod)
print(paste("step is "  ,toString(Step)))
PresentPoint <- Parameters
StepToPoint <- Parameters + GradientVectorNormalised
print(Parameters)
print(GradientVectorNormalised)
print(StepToPoint)
LLLoop <- 0
# Adding GradientVectorNormalised until we have maxemised the LL
while(LL(Match_Data, Parameters=StepToPoint) > LL(Match_Data, Parameters=PresentPoint)){
PresentPoint <- StepToPoint
StepToPoint <- PresentPoint + GradientVectorNormalised
LLLoop <- LLLoop + 1
}
print(paste("LLLoop is "  ,toString(LLLoop)))
# If there has been less than one itteration in the while loop and the step size is smaller than the maximum, then we increase the step size
if((LLLoop < 2 & Step != n | Step == n & LLLoop == 0) & DevideByNMod){
Mult <- Mult + 1
Step <- Mult*m
}
Parameters <- PresentPoint
}
# Second bit to adjust Gamma
# Working out if we need to increase or decrease gamma
sign <- GradientVectorFinder(Match_Data, Parameters)[-2]/abs(GradientVectorFinder(Match_Data, Parameters)[-2])
print(sign)
print(GradientVectorFinder(Match_Data, Parameters))
Alpha <- Parameters[1:length(Teams)]
Beta <- Parameters[(length(Teams)+1):(length(Teams)*2)]
Gamma <- Parameters[length(Teams)*2+1]
Rho <- Parameters[length(Teams)*2+2]
Results <- data.frame(Teams, Alpha, Beta, Gamma, Rho)
return(Results)
}
# prints
Results <- Optimise(Match_Data, DevideByNMod = TRUE, Condition = 0) # If we run this, we will se that all params but gamma are in good shape. could have 2nd bit where we optemise thi
Optimise <- function(Match_Data,n = 100 , m = 10 , DevideByNMod = FALSE, Condition = 0.01){
# Takes some match data and returns
Teams <- sort(unique(Match_Data$HomeTeam))
# Setting all Parameters equal to 1 at first
Parameters <- rep(1,2*length(Teams)+2)
# Setting gamma equal to 1.4 and rho equal to 0
Parameters[2*length(Teams)+1] <- 1.4
Parameters[2*length(Teams)+2] <- -0.05
# Making StartParameters
StartParameters <- rep(0,2*length(Teams)+2)
# Setting the multiplier and step, step is how big the gradient vector is (invesly proportional)
Mult <- 0
Step <- 0
if(DevideByNMod){
Mult <- 1
Step <- m
}
count <- 0
# NMod just finds the length betweent he vectores
while(NMod(Parameters-StartParameters,1) > Condition | (Mult < ((n/m)+1) & DevideByNMod)){
count <- count + 1
print(paste("count is "  ,toString(count)))
# Saving what wha have from the start
StartParameters <- Parameters
# Finding gradient
GradientVector <- GradientVectorFinder(Match_Data, Parameters)
# Normalising (Avergage of alhpas is 1), and adjusting the length
GradientVectorNormalised <- NormalisingTheGradientVector(GradientVector,Step, DevideByNMod = DevideByNMod)
print(paste("step is "  ,toString(Step)))
PresentPoint <- Parameters
StepToPoint <- Parameters + GradientVectorNormalised
print(Parameters)
print(GradientVectorNormalised)
print(StepToPoint)
LLLoop <- 0
# Adding GradientVectorNormalised until we have maxemised the LL
while(LL(Match_Data, Parameters=StepToPoint) > LL(Match_Data, Parameters=PresentPoint)){
PresentPoint <- StepToPoint
StepToPoint <- PresentPoint + GradientVectorNormalised
LLLoop <- LLLoop + 1
}
print(paste("LLLoop is "  ,toString(LLLoop)))
# If there has been less than one itteration in the while loop and the step size is smaller than the maximum, then we increase the step size
if((LLLoop < 2 & Step != n | Step == n & LLLoop == 0) & DevideByNMod){
Mult <- Mult + 1
Step <- Mult*m
}
Parameters <- PresentPoint
}
# Second bit to adjust Gamma
# Working out if we need to increase or decrease gamma
sign <- GradientVectorFinder(Match_Data, Parameters)[-2]/abs(GradientVectorFinder(Match_Data, Parameters)[-2])
print(sign)
print(GradientVectorFinder(Match_Data, Parameters))
Alpha <- Parameters[1:length(Teams)]
Beta <- Parameters[(length(Teams)+1):(length(Teams)*2)]
Gamma <- Parameters[length(Teams)*2+1]
Rho <- Parameters[length(Teams)*2+2]
Results <- data.frame(Teams, Alpha, Beta, Gamma, Rho)
return(Results)
}
# prints
Results <- Optimise(Match_Data, DevideByNMod = TRUE, Condition = 0) # If we run this, we will se that all params but gamma are in good shape. could have 2nd bit where we optemise thi
